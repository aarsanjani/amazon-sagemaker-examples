{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Insurance Fraud Detection - Part 1 : Data Prep to Feature Store "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Life-cycle Detailed View\n",
    "In this end to end example, we will build a model to predict fraudulent insurance claims and deploy it with SageMaker so it can be accessed to provide realtime predictions. While a deployed model is the end-product of this guide, the purpose of this guide is to walk you through the entire machine leanring (ML) lifecyle using SageMaker and AWS. \n",
    "\n",
    "![title](images/ml-lifecycle-detailed.png)\n",
    "\n",
    "The goal of this end-to-end example is to show how SageMaker Servies and Features can be used to support each task in the ML Lifecycle. We will show you how all the various pieces fit together as one cohesive workflow. \n",
    "\n",
    "### Exploratory Data Science and Scalable MLOps\n",
    "\n",
    "Note that there are typically two workflows, the first is the more *exploratory, manual data science workflow* where experiments are conducted and various techniques and strategies are tested. Then, once you have established your data prep transformations, featurizations and  training algorithms, even the testing of various hyperparameters for model tuning> Then you can start with the second thread where you *rely on MLOps or the ML Engineering part of your team* to streamline the process, make it more repetable and scalable by putting it into an automated pipeline. \n",
    "\n",
    "### Car Insurance Claims : Data Sets and Problem Domain\n",
    "\n",
    "The inputs for building our model and workflow are two tables of insurance data: a claims table and a customers table. This data was synthetically generated is provided to you in its raw state for pre-processing with SageMaker Data Wrangler. However, completing the Data Wragnler step is not required to continue with the rest of this notebook. If you wish, you may use the `claims_preprocessed.csv` and `customers_preprocessed.csv` in the `data` directory as they are exact copies of what Data Wragnler would output.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='all-up-overview'></a>\n",
    "\n",
    "## [Overview](./0-AutoClaimFraudDetection.ipynb)\n",
    "* ### [Notebook 0 : Architecture](./0-AutoClaimFraudDetection.ipynb)\n",
    "* ### [Notebook 1: Data Prep, Process, Store Features](./1-data-prep-e2e.ipynb)\n",
    "  * #### [Architecture](#arch)\n",
    "  * #### [Getting started](#aud-getting-started)\n",
    "  * #### [DataSets](#aud-datasets)\n",
    "  * #### [SageMaker Feature Store](#aud-feature-store)\n",
    "  * #### [Create train and test datasets](#aud-dataset)\n",
    "* ### [Notebook 2](./2-lineage-train-assess-bias-tune-registry-e2e.ipynb)\n",
    "  * #### [Train a model using XGBoost](#aud-train-model)\n",
    "  * #### [Model lineage with artifacts and associations](#model-lineage)\n",
    "  * #### [Evaluate the model for bias with Clarify](#check-bias)\n",
    "  * #### [Deposit Model and Lineage in SageMaker Model Registry](#model-registry)\n",
    "* ### [Notebook 3](./3-mitigate-bias-train-model2-registry-e2e.ipynb)\n",
    "  * #### Train a version 2.0 model\n",
    "* ### [Notebook 4](./4-deploy-run-inference-e2e.ipynb)\n",
    "  * #### Deploy an approved model and make prediction\n",
    "* ### [Notebook 5](./5-pipeline-e2e.ipynb)\n",
    "  * #### SageMaker Pipeline\n",
    "  * #### Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='arch'> </a>\n",
    "### Architecture for Data Prep, Process and Store Features\n",
    "![Data Prep and Store](./images/e2e-1-pipeline-v3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading stored variables\n",
    "If you ran this notebook before, you may want to re-use the resources you aready created with AWS. Run the cell below to load any prevously created variables. You should see a print-out of the existing variables. If you don't see anything printed then it's probably the first time you are running the notebook! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bucket                          -> 'sagemaker-us-east-2-738335684114'\n",
      "claims_fg_name                  -> 'fraud-detect-demo-claims'\n",
      "claims_table                    -> 'fraud-detect-demo-claims-1610061189'\n",
      "col_order                       -> ['fraud', 'total_claim_amount', 'incident_month', \n",
      "customers_fg_name               -> 'fraud-detect-demo-customers'\n",
      "customers_table                 -> 'fraud-detect-demo-customers-1610061192'\n",
      "database_name                   -> 'sagemaker_featurestore'\n",
      "hyperparameters                 -> {'max_depth': '3', 'eta': '0.2', 'objective': 'bin\n",
      "model_1_name                    -> 'fraud-detect-demo-xgboost-pre-smote'\n",
      "mpg_name                        -> 'fraud-detect-demo'\n",
      "prefix                          -> 'fraud-detect-demo'\n",
      "test_data_uri                   -> 's3://sagemaker-us-east-2-738335684114/fraud-detec\n",
      "train_data_uri                  -> 's3://sagemaker-us-east-2-738335684114/fraud-detec\n",
      "training_job_1_name             -> 'sagemaker-xgboost-2021-01-24-00-54-41-852'\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required and/or update third-party libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q awswrangler==2.2.0 imbalanced-learn==0.7.0 sagemaker==2.23.1 boto3==1.16.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import string\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aud-getting-started'></a>\n",
    "## Getting started: Creating Resources\n",
    "\n",
    "[overview](#all-up-overview)\n",
    "___\n",
    "In order to successfully run this notebook you will need to create some AWS resources. \n",
    "First, an S3 bucket will be created to store all the data for this tutorial. \n",
    "Once created, you will then need to create an AWS Glue role using the IAM console then attach a policy to the S3 bucket to allow FeatureStore access to this notebook. If you've already run this notebook and are picking up where you left off, then running the cells below should pick up the resources you already created without creating any additional resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add FeatureStore policy to Studio's execution role\n",
    "\n",
    "![title](images/iam-policies.png)\n",
    "\n",
    "\n",
    "1. In a separate brower tab go to the IAM section of the AWS Console\n",
    "2. Navigate to the Roles section and select the execution role you're using for your SageMaker Studio user\n",
    "    * If you're not sure what role you're using, run the cell below to print it out\n",
    "3. Attach the <font color='yellow'> AmazonSageMakerFeatureStoreAccess </font> policy to this role. Once attached, the changes take  effect immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Role: AmazonSageMaker-ExecutionRole-20210113T201603\n"
     ]
    }
   ],
   "source": [
    "print('SageMaker Role:', sagemaker.get_execution_role().split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set region, boto3 and SageMaker SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can change this to a region of your choice\n",
    "region = \"us-east-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a directory in the SageMaker default bucket for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing bucket: sagemaker-us-east-2-738335684114/fraud-detect-demo\n"
     ]
    }
   ],
   "source": [
    "if 'bucket' not in locals():\n",
    "    bucket = sagemaker_session.default_bucket()\n",
    "    prefix = 'fraud-detect-demo'\n",
    "    %store bucket\n",
    "    %store prefix\n",
    "    print(f'Creating bucket: {bucket}...')\n",
    "\n",
    "try:\n",
    "    s3_client.create_bucket(Bucket=bucket, ACL='private', CreateBucketConfiguration={'LocationConstraint': region})\n",
    "    print('Create S3 bucket: SUCCESS')\n",
    "    \n",
    "except Exception as e:\n",
    "    if e.response['Error']['Code'] == 'BucketAlreadyOwnedByYou':\n",
    "        print(f'Using existing bucket: {bucket}/{prefix}')\n",
    "    else:\n",
    "        raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======> Tons of output_paths\n",
    "traing_job_output_path = f's3://{bucket}/{prefix}/training_jobs'\n",
    "bias_report_1_output_path = f's3://{bucket}/{prefix}/clarify-bias-1'\n",
    "bias_report_2_output_path = f's3://{bucket}/{prefix}/clarify-bias-2'\n",
    "explainability_output_path = f's3://{bucket}/{prefix}/clarify-explainability'\n",
    "\n",
    "train_data_uri = f's3://{bucket}/{prefix}/data/train/train.csv'\n",
    "test_data_uri = f's3://{bucket}/{prefix}/data/test/test.csv'\n",
    "\n",
    "#=======> variables used for parameterizing the notebook run\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "claify_instance_count = 1\n",
    "clairfy_instance_type = 'ml.c5.xlarge'\n",
    "\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.c5.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload raw data to S3\n",
    "Before you can preprocess the raw data with Data Wrangler, it must exist in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file(Filename='data/claims.csv', Bucket=bucket, Key=f'{prefix}/data/raw/claims.csv')\n",
    "s3_client.upload_file(Filename='data/customers.csv', Bucket=bucket, Key=f'{prefix}/data/raw/customers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update attributes within the  `.flow` file \n",
    "DataWrangler will generate a .flow file. It contains a reference to an S3 bucket used during the Wrangling. This may be different from the one you have as a default in this notebook eg if the Wrangling was done by someone else, you will probably not have access to their bucket and you now need to point to your own S3 bucket so you can actually load the .flow file into Wrangler or access the data.\n",
    "\n",
    "After running the cell below you can open the `claims.flow` and `customers.flow` files and export the data to S3 or you can continue the guide using the provided `data/claims_preprocessed.csv` and `data/customers_preprocessed.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_flow_template_file = \"claims_flow_template\"\n",
    "\n",
    "with open(claims_flow_template_file, 'r') as f:\n",
    "    variables   = {'bucket': bucket, 'prefix': prefix}\n",
    "    template    = string.Template(f.read())\n",
    "    claims_flow = template.substitute(variables)\n",
    "    claims_flow = json.loads(claims_flow)\n",
    "\n",
    "with open('claims.flow', 'w') as f:\n",
    "    json.dump(claims_flow, f)\n",
    "    \n",
    "customers_flow_template_file = \"customers_flow_template\"\n",
    "\n",
    "with open(customers_flow_template_file, 'r') as f:\n",
    "    variables      = {'bucket': bucket, 'prefix': prefix}\n",
    "    template       = string.Template(f.read())\n",
    "    customers_flow = template.substitute(variables)\n",
    "    customers_flow = json.loads(customers_flow)\n",
    "    \n",
    "with open('customers.flow', 'w') as f:\n",
    "    json.dump(customers_flow, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed data from Data Wrangler job\n",
    "If you ran the Data Wrangler jobs from  `claims.flow` and `customers.flow`, you can load your preprocessed data here. If you did not run the Data Wrangler job, you can still get started by loading the pre-made data sets from the `/data` directory of this example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aud-datasets'></a>\n",
    "#### DataSets and Feature Types\n",
    "\n",
    "[overview](#all-up-overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_dtypes = {'policy_id': int,\n",
    " 'incident_severity': int,\n",
    " 'num_vehicles_involved': int,\n",
    " 'num_injuries': int,\n",
    " 'num_witnesses': int,\n",
    " 'police_report_available': int,\n",
    " 'injury_claim': float,\n",
    " 'vehicle_claim': float,\n",
    " 'total_claim_amount': float,\n",
    " 'incident_month': int,\n",
    " 'incident_day': int,\n",
    " 'incident_dow': int,\n",
    " 'incident_hour': int,\n",
    " 'fraud': int,\n",
    " 'driver_relationship_self': int,\n",
    " 'driver_relationship_na': int,\n",
    " 'driver_relationship_spouse': int,\n",
    " 'driver_relationship_child': int,\n",
    " 'driver_relationship_other': int,\n",
    " 'incident_type_collision': int,\n",
    " 'incident_type_breakin': int,\n",
    " 'incident_type_theft': int,\n",
    " 'collision_type_front': int,\n",
    " 'collision_type_rear': int,\n",
    " 'collision_type_side': int,\n",
    " 'collision_type_na': int,\n",
    " 'authorities_contacted_police': int,\n",
    " 'authorities_contacted_none': int,\n",
    " 'authorities_contacted_fire': int,\n",
    " 'authorities_contacted_ambulance': int,\n",
    " 'event_time': float}\n",
    "\n",
    "customers_dtypes = {'policy_id': int,\n",
    " 'customer_age': int,\n",
    " 'customer_education': int,\n",
    " 'months_as_customer': int,\n",
    " 'policy_deductable': int,\n",
    " 'policy_annual_premium': int,\n",
    " 'policy_liability': int,\n",
    " 'auto_year': int,\n",
    " 'num_claims_past_year': int,\n",
    " 'num_insurers_past_5_years': int,\n",
    " 'customer_gender_male': int,\n",
    " 'customer_gender_female': int,\n",
    " 'policy_state_ca': int,\n",
    " 'policy_state_wa': int,\n",
    " 'policy_state_az': int,\n",
    " 'policy_state_or': int,\n",
    " 'policy_state_nv': int,\n",
    " 'policy_state_id': int,\n",
    " 'event_time': float}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to load Data Wrangler output. Loading pre-made dataframes...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "#======> This is your DataFlow output path if you decide to redo the work in DataFlow on your own\n",
    "flow_output_path = 'YOUR_PATH_HERE'\n",
    "\n",
    "try:\n",
    "    # this will try to load the exported dataframes from the claims and customers .flow files\n",
    "    claims_s3_path = f'{flow_output_path}/claims_output'\n",
    "    customers_s3_path = f'{flow_output_path}/customers_output'\n",
    "    \n",
    "    claims_preprocessed = wr.s3.read_csv(\n",
    "        path=claims_s3_path, \n",
    "        dataset=True, \n",
    "        index_col=0, \n",
    "        dtype=claims_dtypes)\n",
    "    \n",
    "    customers_preprocessed = wr.s3.read_csv(\n",
    "        path=customers_s3_path, \n",
    "        dataset=True, \n",
    "        index_col=0, \n",
    "        dtype=customers_dtypes)\n",
    "\n",
    "except:\n",
    "    # if the Data Wrangler job was not run, the claims and customers dataframes will be loaded from local copies\n",
    "    timestamp = pd.to_datetime('now').timestamp()\n",
    "    print('Unable to load Data Wrangler output. Loading pre-made dataframes...')\n",
    "    \n",
    "    claims_preprocessed = pd.read_csv(\n",
    "        filepath_or_buffer='data/claims_preprocessed.csv', \n",
    "        dtype=claims_dtypes)\n",
    "    \n",
    "    # a timestamp column is required by the feature store, so one is added with a current timestamp\n",
    "    claims_preprocessed['event_time'] = timestamp\n",
    "    \n",
    "    customers_preprocessed = pd.read_csv(\n",
    "        filepath_or_buffer='data/customers_preprocessed.csv', \n",
    "        dtype=customers_dtypes)\n",
    "    \n",
    "    customers_preprocessed['event_time'] = timestamp\n",
    "    \n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a set of Pandas DataFrames that contain the customer and claim data, with the correct data types. When Dat Wrangler encodes a feature as one-hot-encoded feature, it will default to float data types for those resulting features (one feature --> many columns for the one hot encoding). \n",
    "\n",
    "<font color ='red'> Note: </font> the reason for explicitly converting the data types for categorical features generated by Data Wrangler, is to ensure they are of type integer so that Clarify will treat them as categorical variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aud-feature-store'></a>\n",
    "## SageMaker Feature Store\n",
    "\n",
    "[overview](#all-up-overview)\n",
    "___\n",
    "Amazon SageMaker Feature Store is a purpose-built repository where you can store and access features so it’s much easier to name, organize, and reuse them across teams. SageMaker Feature Store provides a unified store for features during training and real-time inference without the need to write additional code or create manual processes to keep features consistent. SageMaker Feature Store keeps track of the metadata of stored features (e.g. feature name or version number) so that you can query the features for the right attributes in batches or in real time using Amazon Athena, an interactive query service. SageMaker Feature Store also keeps features updated, because as new data is generated during inference, the single repository is updated so new features are always available for models to use during training and inference.\n",
    "\n",
    "A feature store consists of an offline componet stored in S3 and an online component stored in a low-latency database. The online database is optional, but very useful if you need supplemental features to be available at inference. In this section, we will create a feature groups for our Claims and Customers datasets. After inserting the claims and customer data into their respective feature groups, you need to query the offline store with Athena to build the training dataset.\n",
    "\n",
    "You can reference the [SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.html) for more information about the SageMaker Feature Store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore_runtime = boto_session.client(\n",
    "    service_name='sagemaker-featurestore-runtime', \n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the feature groups\n",
    "The datatype for each feature is set by passing a dataframe and inferring the proper datatype. Feature data types can also be set via a config variable, but it will have to match the correspongin Python data type in the Pandas dataframe when it's ingested to the Feature Group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'claims_fg_name' (str)\n",
      "Stored 'customers_fg_name' (str)\n"
     ]
    }
   ],
   "source": [
    "claims_fg_name = f'{prefix}-claims'\n",
    "customers_fg_name = f'{prefix}-customers'\n",
    "%store claims_fg_name \n",
    "%store customers_fg_name\n",
    "\n",
    "claims_feature_group = FeatureGroup(\n",
    "    name=claims_fg_name, \n",
    "    sagemaker_session=feature_store_session)\n",
    "\n",
    "customers_feature_group = FeatureGroup(\n",
    "    name=customers_fg_name, \n",
    "    sagemaker_session=feature_store_session)\n",
    "\n",
    "claims_feature_group.load_feature_definitions(data_frame=claims_preprocessed);\n",
    "customers_feature_group.load_feature_definitions(data_frame=customers_preprocessed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the feature groups\n",
    "You must tell the Feature Group which columns in the dataframe correspond to the required record indentifier and event time features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing feature group: fraud-detect-demo-claims\n",
      "Using existing feature group: fraud-detect-demo-customers\n"
     ]
    }
   ],
   "source": [
    "record_identifier_feature_name = 'policy_id'\n",
    "event_time_feature_name = 'event_time'\n",
    "\n",
    "try:\n",
    "    claims_feature_group.create(\n",
    "        s3_uri=f\"s3://{bucket}/{prefix}\",\n",
    "        record_identifier_name=record_identifier_feature_name,\n",
    "        event_time_feature_name=event_time_feature_name,\n",
    "        role_arn=sagemaker_role,\n",
    "        enable_online_store=True\n",
    "    )\n",
    "    print(f'Create \"claims\" feature group: SUCCESS')\n",
    "except Exception as e:\n",
    "    code = e.response.get('Error').get('Code')\n",
    "    if code == 'ResourceInUse':\n",
    "        print(f'Using existing feature group: {claims_fg_name}')\n",
    "    else:\n",
    "        raise(e)\n",
    "\n",
    "try:\n",
    "    customers_feature_group.create(\n",
    "        s3_uri=f\"s3://{bucket}/{prefix}\",\n",
    "        record_identifier_name=record_identifier_feature_name,\n",
    "        event_time_feature_name=event_time_feature_name,\n",
    "        role_arn=sagemaker_role,\n",
    "        enable_online_store=True\n",
    "    )\n",
    "    print(f'Create \"customers\" feature group: SUCCESS')\n",
    "except Exception as e:\n",
    "    code = e.response.get('Error').get('Code')\n",
    "    if code == 'ResourceInUse':\n",
    "        print(f'Using existing feature group: {customers_fg_name}')\n",
    "    else:\n",
    "        raise(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait until feature group creation has fully completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureGroup fraud-detect-demo-claims successfully created.\n",
      "FeatureGroup fraud-detect-demo-customers successfully created.\n"
     ]
    }
   ],
   "source": [
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "    \n",
    "wait_for_feature_group_creation_complete(feature_group=claims_feature_group)\n",
    "wait_for_feature_group_creation_complete(feature_group=customers_feature_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest records into the Feature Groups\n",
    "After the Feature Groups have been created, we can put data into each store by using the PutRecord API. This API can handle high TPS and is designed to be called by different streams. The data from all of these Put requests is buffered and written to s3 in chunks. The files will be written to the offline store within a few minutes of ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You may have already ingested the data into your Feature Groups. If you'd like to do this again, you can run the ingest methods outside of the 'if/else' statement.\n"
     ]
    }
   ],
   "source": [
    "if 'claims_table' in locals():\n",
    "    print(\"You may have already ingested the data into your Feature Groups. If you'd like to do this again, you can run the ingest methods outside of the 'if/else' statement.\")\n",
    "\n",
    "else:\n",
    "    claims_feature_group.ingest(\n",
    "    data_frame=claims_preprocessed, max_workers=3, wait=True\n",
    "    );\n",
    "\n",
    "    customers_feature_group.ingest(\n",
    "        data_frame=customers_preprocessed, max_workers=3, wait=True\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for offline store data to become available\n",
    "This usually takes 5-8 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data available.\n"
     ]
    }
   ],
   "source": [
    "claims_feature_group_s3_prefix = f'{prefix}/{account_id}/sagemaker/{region}/offline-store/{claims_fg_name}/data'\n",
    "customers_feature_group_s3_prefix = f'{prefix}/{account_id}/sagemaker/{region}/offline-store/{customers_fg_name}/data'\n",
    "\n",
    "offline_store_contents = None\n",
    "while (offline_store_contents is None):\n",
    "    objects_in_bucket = s3_client.list_objects(Bucket=bucket, Prefix=customers_feature_group_s3_prefix)\n",
    "    if ('Contents' in objects_in_bucket and len(objects_in_bucket['Contents']) > 1):\n",
    "        offline_store_contents = objects_in_bucket['Contents']\n",
    "    else:\n",
    "        print('Waiting for data in offline store...')\n",
    "        time.sleep(60)\n",
    "    \n",
    "print('\\nData available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aud-dataset'></a>\n",
    "## Create train and test datasets\n",
    "\n",
    "[overview](#all-up-overview)\n",
    "___\n",
    "Once the data is available in the offline store, it will automatically be cataloged and loaded into an Athena table (this is done by default, but can be turned off). In order to build our training and test datasets, you will submit a SQL query to join the the Claims and Customers tables created in Athena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'claims_table' (str)\n",
      "Stored 'customers_table' (str)\n",
      "Stored 'database_name' (str)\n"
     ]
    }
   ],
   "source": [
    "claims_query = claims_feature_group.athena_query()\n",
    "customers_query = customers_feature_group.athena_query()\n",
    "\n",
    "claims_table = claims_query.table_name\n",
    "customers_table = customers_query.table_name\n",
    "database_name = customers_query.database\n",
    "%store claims_table\n",
    "%store customers_table\n",
    "%store database_name\n",
    "\n",
    "feature_columns = list( set(claims_preprocessed.columns) ^ set(customers_preprocessed.columns) )\n",
    "feature_columns_string = \", \".join(f'\\\"{c}\\\"' for c in feature_columns)\n",
    "feature_columns_string = f'\"{claims_table}\".policy_id as policy_id, ' + feature_columns_string\n",
    "\n",
    "query_string = f\"\"\"\n",
    "SELECT DISTINCT {feature_columns_string}\n",
    "FROM \"{claims_table}\" LEFT JOIN \"{customers_table}\" \n",
    "ON \"{claims_table}\".policy_id = \"{customers_table}\".policy_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_query.run(query_string=query_string, output_location=f's3://{bucket}/{prefix}/query_results')\n",
    "claims_query.wait()\n",
    "dataset = claims_query.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"./data/claims_customer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'col_order' (list)\n"
     ]
    }
   ],
   "source": [
    "col_order = ['fraud'] + list(dataset.drop(['fraud', 'policy_id'], axis=1).columns)\n",
    "%store col_order\n",
    "\n",
    "train = dataset.sample(frac=.80, random_state=0)[col_order]\n",
    "test = dataset.drop(train.index)[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write train, test data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/train.csv', index=False)\n",
    "test.to_csv('data/test.csv', index=False)\n",
    "dataset.to_csv('data/dataset.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_data_uri' (str)\n",
      "Stored 'test_data_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "s3_client.upload_file(Filename='data/train.csv', Bucket=bucket, Key=f'{prefix}/data/train/train.csv')\n",
    "s3_client.upload_file(Filename='data/test.csv', Bucket=bucket, Key=f'{prefix}/data/test/test.csv')\n",
    "%store train_data_uri\n",
    "%store test_data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "      <th>incident_type_theft</th>\n",
       "      <th>policy_state_ca</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>num_witnesses</th>\n",
       "      <th>policy_state_or</th>\n",
       "      <th>incident_month</th>\n",
       "      <th>customer_gender_female</th>\n",
       "      <th>num_insurers_past_5_years</th>\n",
       "      <th>customer_gender_male</th>\n",
       "      <th>...</th>\n",
       "      <th>driver_relationship_other</th>\n",
       "      <th>policy_state_id</th>\n",
       "      <th>incident_hour</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>incident_type_collision</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>policy_state_az</th>\n",
       "      <th>policy_state_wa</th>\n",
       "      <th>collision_type_rear</th>\n",
       "      <th>collision_type_front</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>27774.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16643</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>31452.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19117</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>14153.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fraud  incident_type_theft  policy_state_ca  policy_deductable  \\\n",
       "19134      0                    0                1                750   \n",
       "4981       0                    0                1                750   \n",
       "16643      0                    0                1                750   \n",
       "19117      0                    0                1                750   \n",
       "5306       0                    0                0                750   \n",
       "\n",
       "       num_witnesses  policy_state_or  incident_month  customer_gender_female  \\\n",
       "19134              2                0               5                       1   \n",
       "4981               2                0               6                       1   \n",
       "16643              2                0               6                       0   \n",
       "19117              2                0              11                       1   \n",
       "5306               0                0               8                       0   \n",
       "\n",
       "       num_insurers_past_5_years  customer_gender_male  ...  \\\n",
       "19134                          1                     0  ...   \n",
       "4981                           1                     0  ...   \n",
       "16643                          1                     1  ...   \n",
       "19117                          1                     0  ...   \n",
       "5306                           1                     0  ...   \n",
       "\n",
       "       driver_relationship_other  policy_state_id  incident_hour  \\\n",
       "19134                          0                0             18   \n",
       "4981                           0                0             20   \n",
       "16643                          0                0              9   \n",
       "19117                          0                0             21   \n",
       "5306                           0                0             10   \n",
       "\n",
       "       vehicle_claim  incident_type_collision  policy_annual_premium  \\\n",
       "19134        27774.0                        1                   3000   \n",
       "4981         24000.0                        1                   3000   \n",
       "16643        31452.0                        1                   2850   \n",
       "19117        14153.0                        1                   2900   \n",
       "5306          6000.0                        1                   3000   \n",
       "\n",
       "       policy_state_az  policy_state_wa  collision_type_rear  \\\n",
       "19134                0                0                    1   \n",
       "4981                 0                0                    1   \n",
       "16643                0                0                    1   \n",
       "19117                0                0                    0   \n",
       "5306                 0                0                    0   \n",
       "\n",
       "       collision_type_front  \n",
       "19134                     0  \n",
       "4981                      0  \n",
       "16643                     0  \n",
       "19117                     1  \n",
       "5306                      1  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "      <th>incident_type_theft</th>\n",
       "      <th>policy_state_ca</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>num_witnesses</th>\n",
       "      <th>policy_state_or</th>\n",
       "      <th>incident_month</th>\n",
       "      <th>customer_gender_female</th>\n",
       "      <th>num_insurers_past_5_years</th>\n",
       "      <th>customer_gender_male</th>\n",
       "      <th>...</th>\n",
       "      <th>driver_relationship_other</th>\n",
       "      <th>policy_state_id</th>\n",
       "      <th>incident_hour</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>incident_type_collision</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>policy_state_az</th>\n",
       "      <th>policy_state_wa</th>\n",
       "      <th>collision_type_rear</th>\n",
       "      <th>collision_type_front</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>34500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fraud  incident_type_theft  policy_state_ca  policy_deductable  \\\n",
       "10      0                    0                1                750   \n",
       "19      0                    0                0                750   \n",
       "28      0                    0                1                750   \n",
       "40      0                    0                0                750   \n",
       "43      0                    0                0                750   \n",
       "\n",
       "    num_witnesses  policy_state_or  incident_month  customer_gender_female  \\\n",
       "10              1                0               9                       1   \n",
       "19              1                0               5                       0   \n",
       "28              0                0               4                       0   \n",
       "40              5                0              10                       1   \n",
       "43              1                0               8                       1   \n",
       "\n",
       "    num_insurers_past_5_years  customer_gender_male  ...  \\\n",
       "10                          1                     0  ...   \n",
       "19                          1                     1  ...   \n",
       "28                          1                     1  ...   \n",
       "40                          5                     0  ...   \n",
       "43                          1                     0  ...   \n",
       "\n",
       "    driver_relationship_other  policy_state_id  incident_hour  vehicle_claim  \\\n",
       "10                          0                0              1        37000.0   \n",
       "19                          0                0             18        34500.0   \n",
       "28                          0                0             18        12000.0   \n",
       "40                          0                0             15        14000.0   \n",
       "43                          0                0              3        35000.0   \n",
       "\n",
       "    incident_type_collision  policy_annual_premium  policy_state_az  \\\n",
       "10                        1                   3000                0   \n",
       "19                        1                   2700                0   \n",
       "28                        0                   3000                0   \n",
       "40                        1                   2750                1   \n",
       "43                        1                   3000                0   \n",
       "\n",
       "    policy_state_wa  collision_type_rear  collision_type_front  \n",
       "10                0                    0                     1  \n",
       "19                1                    1                     0  \n",
       "28                0                    0                     0  \n",
       "40                0                    0                     1  \n",
       "43                1                    1                     0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
