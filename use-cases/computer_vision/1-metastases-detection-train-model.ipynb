{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision for Medical Imaging\n",
    "## Part 1  - Train Model with Hyperparameter Tuning Job\n",
    "This notebook is part 1 of a 4-part series of techniques and services offer by SageMaker to build a model which predicts if an image of cells contains cancer. This notebook shows how to build a model using hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset chose for this demo comes from the [Camelyon16 Challenge](https://camelyon16.grand-challenge.org/) made available under the CC0 licencse. The raw data provided by the challenge has been processed into 96x96 pixel tiles by [Bas Veeling](https://github.com/basveeling/pcam) and also made available under the CC0 license. For detailed information on each dataset please see the papers below:\n",
    "* Ehteshami Bejnordi et al. Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer. JAMA: The Journal of the American Medical Association, 318(22), 2199â€“2210. [doi:jama.2017.14585](https://doi.org/10.1001/jama.2017.14585)\n",
    "* B. S. Veeling, J. Linmans, J. Winkens, T. Cohen, M. Welling. \"Rotation Equivariant CNNs for Digital Pathology\". [arXiv:1806.03962](http://arxiv.org/abs/1806.03962)\n",
    "\n",
    "The tiled dataset from Bas Veeling is over 6GB of data. In order to easily run this demo, the dataset has been pruned to the first 14,000 images of the tiled dataset and comes included in the repo with this notebook for convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Sagemaker SDK and Boto3\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>NOTE</b> You may get an error from pip's dependency resolver; you can ignore this error.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q sagemaker==2.23.1 boto3==1.16.48 mxnet opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import h5py\n",
    "import zipfile\n",
    "import boto3\n",
    "import sagemaker\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Boto3 Clients and Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"us-east-2\"\n",
    "boto3.setup_default_session(region_name=region)\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if directory exists\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "# download zip file from public s3 bucket\n",
    "!wget -P data https://sagemaker-sample-files.s3.amazonaws.com/datasets/image/pcam/medical_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('data/medical_images.zip') as zf:\n",
    "    zf.extractall()\n",
    "    with zf.open('data/camelyon16_tiles.h5') as hf:\n",
    "        f = h5py.File(hf,'r')\n",
    "        \n",
    "        X = f['x'][()]\n",
    "        y = f['y'][()]\n",
    "        \n",
    "print('Shape of X:', X.shape)\n",
    "print('Shape of y:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to session s3 bucket\n",
    "s3_client.upload_file('data/medical_images.zip', bucket, f'data/medical_images.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete local copy\n",
    "import os\n",
    "if os.path.exists(\"data/medical_images.zip\"):\n",
    "    os.remove(\"data/medical_images.zip\")\n",
    "else:\n",
    "    print(\"The file does not exist\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Sample Images from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_images(X, y, n, cols):\n",
    "    sample_images = X[:n]\n",
    "    sample_labels = y[:n]\n",
    "\n",
    "    rows = int(np.ceil(n/cols))\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(11.5, 7))\n",
    "\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        image = sample_images[i]\n",
    "        label = sample_labels[i]\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Label: {label}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "preview_images(X, y, 15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_numpy = X[:]\n",
    "y_numpy = y[:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_numpy, y_numpy, test_size=1000, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=2000, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Splits to RecordIO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_recordio(X: np.ndarray, y: np.ndarray, prefix: str):\n",
    "    record = mx.recordio.MXIndexedRecordIO(idx_path=f'{prefix}.idx', uri=f'{prefix}.rec', flag='w')\n",
    "    for idx, arr in enumerate(tqdm(X)):\n",
    "        header = mx.recordio.IRHeader(0, y[idx], idx, 0)\n",
    "        s = mx.recordio.pack_img(header, arr, quality=95, img_fmt='.jpg',)\n",
    "        record.write_idx(idx, s)\n",
    "    record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_recordio(X_train, y_train, prefix='data/train')\n",
    "write_to_recordio(X_val, y_val, prefix='data/val')\n",
    "write_to_recordio(X_test, y_test, prefix='data/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data Splits to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'cv-metastasis'\n",
    "\n",
    "try:\n",
    "    s3_client.create_bucket(Bucket=bucket, ACL='private', CreateBucketConfiguration={'LocationConstraint': region})\n",
    "    print(f'Created S3 bucket: {bucket}')\n",
    "    \n",
    "except Exception as e:\n",
    "    if e.response['Error']['Code'] == 'BucketAlreadyOwnedByYou':\n",
    "        print(f'Using existing bucket: {bucket}')\n",
    "    else:\n",
    "        raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file('data/train.rec', bucket, f'{prefix}/data/train/train.rec')\n",
    "s3_client.upload_file('data/val.rec', bucket, f'{prefix}/data/val/val.rec')\n",
    "s3_client.upload_file('data/test.rec', bucket, f'{prefix}/data/test/test.rec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = sagemaker.image_uris.retrieve('image-classification', region)\n",
    "num_training_samples = X_train.shape[0]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "hyperparameters = {\n",
    "    'num_layers': 18,\n",
    "    'use_pretrained_model': 1,\n",
    "    'augmentation_type': 'crop_color_transform',\n",
    "    'image_shape': \"3,96,96\",\n",
    "    'num_classes': num_classes,\n",
    "    'num_training_samples': num_training_samples,\n",
    "    'mini_batch_size': 64,\n",
    "    'epochs': 5,\n",
    "    'learning_rate': 0.01,\n",
    "    'precision_dtype': 'float32'\n",
    "}\n",
    "\n",
    "estimator_config = {\n",
    "    'hyperparameters': hyperparameters,\n",
    "    'image_uri': training_image,\n",
    "    'role': sagemaker.get_execution_role(), \n",
    "    'instance_count': 1, \n",
    "    'instance_type': 'ml.p3.2xlarge',\n",
    "    'volume_size': 100,\n",
    "    'max_run': 360000,\n",
    "    'output_path': f's3://{bucket}/{prefix}/training_jobs'\n",
    "}\n",
    "\n",
    "image_classifier = sagemaker.estimator.Estimator(**estimator_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store num_training_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Hyperparameter Tuner\n",
    "\n",
    "Although we would prefer to tune for recall, the current HyperparameterTuner implementation for Image Classification only supports validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'mini_batch_size': sagemaker.parameter.CategoricalParameter([16, 32, 64]),\n",
    "    'learning_rate': sagemaker.parameter.CategoricalParameter([.001, .01])\n",
    "}\n",
    "\n",
    "hyperparameter_tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=image_classifier, \n",
    "    objective_metric_name='validation:accuracy', \n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    max_jobs=6,\n",
    "    max_parallel_jobs=2,\n",
    "    base_tuning_job_name=prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Data Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = sagemaker.inputs.TrainingInput( \n",
    "    s3_data=f's3://{bucket}/{prefix}/data/train',\n",
    "    content_type='application/x-recordio',\n",
    "    s3_data_type='S3Prefix',\n",
    "    input_mode='Pipe')\n",
    "\n",
    "val_input = sagemaker.inputs.TrainingInput( \n",
    "    s3_data=f's3://{bucket}/{prefix}/data/val',\n",
    "    content_type='application/x-recordio',\n",
    "    s3_data_type='S3Prefix',\n",
    "    input_mode='Pipe')\n",
    "\n",
    "data_channels = {'train': train_input, 'validation': val_input}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Hyperparameter Tuning Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'tuning_job_name' not in locals():\n",
    "    hyperparameter_tuner.fit(inputs=data_channels)\n",
    "    tuning_job_name = hyperparameter_tuner.describe().get('HyperParameterTuningJobName')\n",
    "    %store tuning_job_name\n",
    "else:\n",
    "    print(f'Using previous tuning job: {tuning_job_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store tuning_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Results\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>NOTE:</b> If your kernel has restarted after running the hyperparameter tuning job, everyting you need has been persisted to SageMaker. You can continue on without having to run the tuning job again.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sagemaker.analytics.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "results_df = results.dataframe()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_training_job_summary = results.description()['BestTrainingJob']\n",
    "best_training_job_name = best_training_job_summary['TrainingJobName']\n",
    "\n",
    "%store best_training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
